---
title: "wk6_practical"
output: html_document
---
```{r}
#first library a few packages that we will use during the practical
#note you may need to install them first...
library(spatstat)
library(here)
library(sp)
library(tmap)
library(sf)
library(tmaptools)
```
```{r}
##First, get the London Borough Boundaries
LondonBoroughs <- st_read(here::here("statistical-gis-boundaries-london", "ESRI", "London_Borough_Excluding_MHW.shp"))
```
```{r}
# Or use this to read in directly.
#LondonBoroughs <- st_read("https://opendata.arcgis.com/datasets/8edafbe3276d4b56aec60991cbddda50_4.geojson")
```

```{r}
library(stringr)
BoroughMap <- LondonBoroughs %>%
  dplyr::filter(str_detect(GSS_CODE, "^E09"))%>%
  st_transform(., 27700)

qtm(BoroughMap)
```
```{r}
summary(BoroughMap)
```
```{r}
##Now get the location of all Blue Plaques in the City
BluePlaques <- st_read("https://s3.eu-west-2.amazonaws.com/openplaques/open-plaques-london-2023-11-10.geojson")
```

```{r}
#或者在本地文件夹中读取
#BluePlaques <- st_read(here::here("open-plaques-london-2018-04-08.geojson")) %>%
#st_transform(.,27700)
```

```{r}
summary(BluePlaques)
```
```{r}

#plot the blue plaques in the city
tmap_mode("plot")

tm_shape(BoroughMap) +
  tm_polygons(fill_alpha = 0.5)+
tm_shape(BluePlaques) +
  tm_dots(fill = "blue", size=0.1)
```
##数据清理
```{r}
#remove duplicates
library(tidyverse)

library(sf)
BluePlaques <- distinct(BluePlaques)
```

```{r}
BluePlaques <- BluePlaques %>% 
  st_transform(st_crs(BoroughMap))
```


##空间子集
```{r}
#drops any plaque points that don’t touch/lie within a London borough
BluePlaquesSub <- BluePlaques[BoroughMap,]

#plot the blue plaques in the city
tmap_mode("plot")

#check to see that they've been removed
tm_shape(BoroughMap) +
  tm_polygons(fill_alpha = 0.5)+
tm_shape(BluePlaquesSub) +
  tm_dots(fill = "blue", size=0.1)
```
```{r}
#识别自治市镇轮廓内的点，使用具有它们相交位置的指数的函数
# add sparse=false to get the complete matrix.
# this is the same as select by location in QGIS
# filter from dplyr is the same as select by attribute 
intersect_indices <-st_intersects(BoroughMap, BluePlaques)
```

##Spatial clipping空间剪切
用于分层并提取，寻找两个不同数据集的多边形在哪里重叠
Select points or polygons in a polygon (Selecting data by location) = spatial sub-setting. This is just presence or absence within (or whatever function we use) an sf object.在多边形中选择点或多边形（按位置选择数据）=空间子设置。这只是在sf对象中（或我们使用的任何功能）中的存在或不存在       

Determine where datasets overlap (or touch, or don’t overlap) and extract those parts = spatial clipping 确定数据集重叠的位置（或触摸或不重叠）并提取这些部分=空间剪切

Join two spatial datasets together = spatial joining, which can use spatial subsetting functions as the default is st_intersects(). This function joins spatial data. 将两个空间数据集连接在一起=空间连接，可以使用空间子集函数，默认为st_intersects()这个函数连接空间数据   

Finally,Selecting data by attributes = filtering or selecting rows / columns with dplyr 按属性选择数据=使用dplyr过滤或选择行/列    


##study area
选择一些单独的的行政区，对sf对象进行子集
```{r}
#extract the borough

# select by attribute
Harrow <- BoroughMap %>%
  filter(., NAME=="Harrow")

#Check to see that the correct borough has been pulled out
tm_shape(Harrow) +
  tm_polygons(col = NA, fill_alpha = 0.5)
```
```{r}
#clip the data to our single borough
BluePlaquesSub <- BluePlaques[Harrow,]



#check that it's worked
tm_shape(Harrow) +
  tm_polygons(fill_alpha = 0.5)+
tm_shape(BluePlaquesSub) +
  tm_dots(fill = "blue", size=0.1)
```
```{r}
#创建一个观察窗口，设置Harrow的边界范围
#now set a window as the borough boundary
window <- as.owin(Harrow)
plot(window)
```
```{r}
#创建点模式分析对象point pattern (ppp) object
#create a sp object
BluePlaquesSub<- BluePlaquesSub %>%
  as(., 'Spatial')
#create a ppp object
BluePlaquesSub.ppp <- ppp(x=BluePlaquesSub@coords[,1],
                          y=BluePlaquesSub@coords[,2],
                          window=window)
```
```{r}
#运行代码元素
BluePlaquesSub@coords[,1]
```
```{r}
#查看新的ppp对象
BluePlaquesSub.ppp %>%
  plot(.,pch=16,cex=0.5, 
       main="Blue Plaques Harrow")
```
##点模式分析
### Kernel Density Estimation(KDE)
```{r}
BluePlaquesSub.ppp %>%
  density(., sigma=500) %>%
  plot()
```
```{r}
#尝试对sigma的不同值实验，看看它如何影响密度估计
BluePlaquesSub.ppp %>%
  density(., sigma=1000) %>%
  plot()
```
###Quadrat Analysis象限分析
```{r}
#First plot the points
plot(BluePlaquesSub.ppp,
     pch=16,
     cex=0.5, 
     main="Blue Plaques in Harrow")

#now count the points in that fall in a 6 x 6
#grid overlaid across the windowBluePlaquesSub.ppp2<-BluePlaquesSub.ppp %>%
BluePlaquesSub.ppp %>%
  quadratcount(.,nx = 6, ny = 6)%>%
    plot(., add=T, col="red")
```
就我们而言，想知道伦敦地区是否存在与蓝牌相关的任何空间模式。如果你从讲座中回忆起，这意味着根据泊松分布，将我们观察到的点分布与统计可能（完全空间随机）分布进行比较


```{r}
#run the quadrat count
Qcount <- BluePlaquesSub.ppp %>%
  quadratcount(.,nx = 6, ny = 6) %>%
  as.data.frame() %>%
  dplyr::count(Var1=Freq)%>%
  dplyr::rename(Freqquadratcount=n)
```

```{r}
#Check the data type in the first column — if it is factor, we will need to convert it to numeric
Qcount %>% 
  summarise_all(class)
```
```{r}
#计算预期值
sums <- Qcount %>%
  #calculate the total blue plaques (Var * Freq)
  mutate(total = Var1 * Freqquadratcount) %>%
  dplyr::summarise(across(everything(), sum))%>%
  dplyr::select(-Var1) 

lambda<- Qcount%>%
  #calculate lambda
  mutate(total = Var1 * Freqquadratcount)%>%
  dplyr::summarise(across(everything(), sum)) %>%
  mutate(lambda=total/Freqquadratcount) %>%
  dplyr::select(lambda)%>%
  pull(lambda)
```

```{r}
#使用上面的泊松公式计算预期值K是以正方形计算的蓝色牌匾的数量，可以在我们表格的第一列中找到......
QCountTable <- Qcount %>%
  mutate(Pr=((lambda^Var1)*exp(-lambda))/factorial(Var1))%>%
  #now calculate the expected counts based on our total number of plaques
  #and save them to the table
  mutate(Expected= (round(Pr * sums$Freqquadratcount, 0)))

#Compare the frequency distributions of the observed and expected point patterns
plot(c(1,5),c(0,14), type="n",
xlab="Number of Blue Plaques (Red=Observed,Blue=Expected)", 
     ylab="Frequency of Occurances")
points(QCountTable$Freqquadratcount, 
       col="Red", 
       type="o", 
       lwd=3)
points(QCountTable$Expected, col="Blue", 
       type="o", 
       lwd=3)
```
限计数的观测频率和预期频率，我们可以观察到它们在低端都有更高的频率计数——这让人联想到泊松分布。这可能表明，对于这组特定的象限，我们的模式接近于完全空间随机性（即没有点的聚类或分散）。但我们如何确认这一点呢？

为了确定，我们可以使用内置在spatstat中的quadrat.test()函数。这使用Chi Squared测试来比较每个象限的观测和预期频率（而不是象限仓，正如我们上面刚刚计算的那样）。

卡方检验确定两个分类变量之间是否存在关联。卡方值越高，差异越大。

如果我们卡方检验的p值<0.05，那么我们可以拒绝一个空假设，即“我们的数据中没有模式——即完全的空间随机性”（将空假设视为空假设的对立面，该假设表明我们的数据表现出一种模式）。我们需要寻找的是p >0.05的值。如果我们的p值>0.05，那么这表明我们有企业社会责任，我们的点没有模式。如果它<0.05，这表明我们的点确实有聚类。

```{r}
teststats <- quadrat.test(BluePlaquesSub.ppp, nx = 6, ny = 6)
```
```{r}
plot(BluePlaquesSub.ppp,pch=16,cex=0.5, main="Blue Plaques in Harrow")
plot(teststats, add=T, col = "red")
```

在这里，我们的p值=0.2594，意味着完全的空间随机性。但像这样使用量子有局限性......我们接下来将探索。

注意警告信息——一些观察到的计数非常小（0），这可能会影响象限测试的准确性。回想一下，泊松分布只描述了以整数计算的观察到的发生情况——如果我们的发生=0（即未观察到），这可能是一个问题。我们也知道，还有其他各种问题可能会影响我们的四边形分析，例如可修改的面位问题。

在新图中，我们可以看到每个象限的三个数字。左上角的图是观察到的点数；右上角是泊松预期点数；底部值是残差值（也称为皮尔逊残差值）或（观察到-预期）/Sqrt（预期）。

##Ripley’s K
```{r}
K <- BluePlaquesSub.ppp %>%
  Kest(., correction="border") %>%
  plot()
```

```{r}
# we can also extract the plot into a dataframe
Kval <- as.data.frame(Kest(BluePlaquesSub.ppp, correction = "Ripley"))
```

Density-based spatial clustering of applications with noise: DBSCAN

```{r}
library(fpc)
```

```{r}
#first check the coordinate reference system of the Harrow spatial polygon:
st_geometry(BoroughMap)
```
DBSCAN要求您输入两个参数：1.Epsilon - 这是搜索集群2的算法的半径。MinPts - 这是应该被视为集群的最低点数

根据之前的里普利K分析结果，我们可以看到，我们的聚类半径约为1200米，图中最大的隆起约为700米。因此，700米可能是一个很好的起点，我们将从寻找至少4个点的集群开始......

```{r}
#first extract the points from the spatial points data frame
BluePlaquesSubPoints <- BluePlaquesSub %>%
  coordinates(.)%>%
  as.data.frame()

#now run the dbscan analysis
db <- BluePlaquesSubPoints %>%
  fpc::dbscan(.,eps = 700, MinPts = 4)

#now plot the results
plot(db, BluePlaquesSubPoints, main = "DBSCAN Output", frame = F)
plot(BoroughMap$geometry, add=T)
```


```{r}
# used to find suitable eps value based on the knee in plot
# k is no of nearest neighbours used, use min points
library(dbscan)

BluePlaquesSubPoints%>%
  dbscan::kNNdistplot(.,k=4)
```

```{r}
library(ggplot2)
```
```{r}
db #摘要
```
```{r}
db$cluster #插槽
```

```{r}
#将此集群会员信息重新添加到我们的数据框架中
BluePlaquesSubPoints<- BluePlaquesSubPoints %>%
  mutate(dbcluster=db$cluster)
```

接下来，我们将创建一些凸壳多边形来包裹聚类中的点。这意味着我们将创建一个最小的多边形，包围每个聚类的点集。我们会
将此数据框架转换为sf对象
在集群周围做凸的船体

```{r}
# convert the data frame to sf
BluePlaquesSubPoints_sf <- st_as_sf(BluePlaquesSubPoints, 
                                    coords = c("coords.x1", "coords.x2"), 
                                    crs = 27700)

# make the convex hulls around the cluster points
chull_polygons <- BluePlaquesSubPoints_sf %>%
  # remove any points not in a cluster
  filter(dbcluster>0)%>%
  group_by(dbcluster) %>%
  summarise(geometry = st_combine(geometry)) %>%  # combine points
  mutate(geometry = st_convex_hull(geometry)) %>% # convex hull
  st_as_sf()
```
 
fill用于内部颜色（类似多边形）
color用于边界和点
```{r}
library(ggspatial)
```

```{r}
# Create the map
ggplot() +
  annotation_map_tile(zoom = 13) +
  geom_sf(data = BluePlaquesSubPoints_sf, aes(color=dbcluster), size = 3)+
  geom_sf(data = chull_polygons, aes(fill = dbcluster), 
          alpha = 0.8, 
          # remove polygon borders
          color = NA, 
          show.legend = FALSE) +

  theme_bw()
```

